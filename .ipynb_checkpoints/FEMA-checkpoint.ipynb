{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from chemproject.dictools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.femaflavor.org/flavor/library/cis-and-trans-l-mercapto-p-menthan-3-one\n",
      ".https://www.femaflavor.org/flavor/library/1-methyl-1h-pyrrole-2-carboxaldehyde\n",
      "."
     ]
    }
   ],
   "source": [
    "test = dictionary_maker([4300, 4332])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{4300: {'CAS': '29725-66-4',\n",
       "  'FEMA': '4300',\n",
       "  'JECFA': '1673',\n",
       "  'descriptors': 'Fruit',\n",
       "  'link': 'https://www.femaflavor.org/flavor/library/cis-and-trans-l-mercapto-p-menthan-3-one',\n",
       "  'name': 'CIS- AND TRANS-L-MERCAPTO-P-MENTHAN-3-ONE',\n",
       "  'rdkit Mol': <rdkit.Chem.rdchem.Mol at 0x112da5d00>,\n",
       "  'tokens': ['fruit']},\n",
       " 4332: {'CAS': '1192-58-1',\n",
       "  'FEMA': '4332',\n",
       "  'JECFA': '2152',\n",
       "  'descriptors': 'Nuts',\n",
       "  'link': 'https://www.femaflavor.org/flavor/library/1-methyl-1h-pyrrole-2-carboxaldehyde',\n",
       "  'name': '1-METHYL-1H-PYRROLE-2-CARBOXALDEHYDE',\n",
       "  'rdkit Mol': <rdkit.Chem.rdchem.Mol at 0x112658bc0>,\n",
       "  'tokens': ['nut']}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('totalDict.pickle', 'wb') as f:\n",
    "    pickle.dump(totalDict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def getDictLists(sourceKey, dictionary=femaDict):\n",
    "    '''\n",
    "    Generator returns key, and result from a dictionary's given sourceKey when available.\n",
    "    If the result is not available returns NoneType\n",
    "    '''\n",
    "    for key in dictionary.keys():\n",
    "        try:\n",
    "            ans = dictionary[key].get(sourceKey)\n",
    "        except:\n",
    "            continue\n",
    "        if ans:\n",
    "            yield key, ans\n",
    "\n",
    "def phraseToSubWord(phraseList, function1, function2):\n",
    "    '''\n",
    "    processes a phrase to a list of words treated by functions 1 and 2\n",
    "    '''\n",
    "    newList = []\n",
    "    for phrase in phraseList:\n",
    "        newPhrase = []\n",
    "        words = phrase.split()\n",
    "        for word in words:\n",
    "            newWord = function1(word)\n",
    "            newWord = function2(newWord)\n",
    "            newPhrase.append(newWord)\n",
    "        ', '.join(newPhrase)\n",
    "        newList.extend(newPhrase)\n",
    "    return newList\n",
    "\n",
    "def dictKeyConverter(function1, function2, sourceKey, newKey, dictionary=femaDict):\n",
    "    '''\n",
    "    Applies phraseToSubWord() to sourceKey in femDict and adds the results to newKey\n",
    "    '''\n",
    "    \n",
    "    stemDescriptors = []\n",
    "    for key, result in getDictLists(sourceKey):\n",
    "        newList = phraseToSubWord(result, \n",
    "                                  function1, \n",
    "                                  function2)\n",
    "        if key == 'single descriptor counts':\n",
    "            print(key, result,newList)\n",
    "        dictionary[key][newKey] = newList\n",
    "    return dictionary\n",
    "\n",
    "def dictSingles(function1, function2, sourceKey, listKey, indexKey, countKey, dictionary=femaDict):\n",
    "    '''\n",
    "    returns input dictionary with a:\n",
    "    -listKey with a set-list of alphabetized descriptors used in a dictionary sourceKey list \n",
    "    as single words, not part of a phrase\n",
    "    -indexKey with a dictionary using the words in the listKey list as keys and an associated index\n",
    "    -countKey with a list of tuples with the count numbers of the single descriptors in the dictionary\n",
    "    '''\n",
    "\n",
    "    #create single descriptor list from the sourceKey entrys in dictionary\n",
    "    singleDescriptors = []\n",
    "    for _, result in getDictLists(sourceKey): \n",
    "        for phrase in result:\n",
    "            if 0 < len(phrase.split()) < 3:\n",
    "                singleDescriptors.append(phrase)\n",
    "    \n",
    "    #process singleDescriptors with two functions, count the occurences and assign count to countKey \n",
    "    singleDescriptors = phraseToSubWord(singleDescriptors,\n",
    "                                        function1,\n",
    "                                        function2)\n",
    "    singleCounter = Counter(singleDescriptors).most_common()\n",
    "    dictionary[countKey] = singleCounter\n",
    "    \n",
    "    #narrow down to a set, sort, and assign singleDescriptor list to listKey\n",
    "    singleList= list(set(singleDescriptors))\n",
    "    singleList.sort()\n",
    "    dictionary[listKey] = singleList\n",
    "    \n",
    "    #create index dictionary of singleList elements for indexKey\n",
    "    descriptorIndices = {}\n",
    "    for i, word in enumerate(singleList):\n",
    "        descriptorIndices[word] = i\n",
    "    dictionary[indexKey] = descriptorIndices\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CAS': '26446-38-8', 'rejected descriptors': ['waxi', 'also', 'help', 'to', 'emulsifi', 'other', 'compon', 'within', 'the', 'flavor', 'formul'], 'name': 'SUCROSE MONOPALMITATE', 'descriptor indices': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'stemmed descriptors': ['fatti', 'waxi', 'can', 'also', 'help', 'to', 'emulsifi', 'other', 'compon', 'within', 'the', 'flavor', 'formul'], 'descriptors': ['fatty', 'waxy; can also help to emulsify other components within the flavor formulation'], 'link': 'http://www.femaflavor.org/flavor/library/sucrose-monopalmitate', 'selected descriptors': ['fatti', 'can'], 'FEMA': '4713', 'rdkit Mol': <rdkit.Chem.rdchem.Mol object at 0x113fbc1f0>}\n"
     ]
    }
   ],
   "source": [
    "from nltk import stem\n",
    "import re\n",
    "\n",
    "pattern = re.compile('[\\W_]+')\n",
    "function1 = lambda x: pattern.sub('', x)\n",
    "stemmer = stem.SnowballStemmer('english')\n",
    "function2 = stemmer.stem\n",
    "\n",
    "femaDict = dictKeyConverter(function1, function2, \n",
    "                            sourceKey='descriptors', \n",
    "                            newKey='stemmed descriptors')\n",
    "\n",
    "femaDict = dictSingles(function1, function2,\n",
    "                       sourceKey='descriptors',\n",
    "                       listKey='single descriptors', \n",
    "                       indexKey='descriptor index pairs', \n",
    "                       countKey='single descriptor counts')\n",
    "\n",
    "print(femaDict['4713'])\n",
    "# print(femaDict['single descriptor counts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def descriptorSelector(listKey, sourceKey, selectKey, rejectKey, dictionary=femaDict):\n",
    "    '''\n",
    "    returns an input dictionary with two new keys based on the input dictionary's sourceKey list:\n",
    "    selectKey has a list containing items found in singleList and the sourceKey list\n",
    "    rejectKey has a list containing items not found in singleList but in the sourceKey list\n",
    "    '''\n",
    "    \n",
    "    for key, result in getDictLists(sourceKey):\n",
    "        selectList = []\n",
    "        rejects = []\n",
    "        for word in result:\n",
    "            #print('word: {} ' .format(word))\n",
    "            if word in dictionary[listKey]:\n",
    "                selectList.append(word)\n",
    "                #print('selectList: {} ' .format(selectList))\n",
    "            else:\n",
    "                rejects.append(word)\n",
    "                #print('rejects: {} ' .format(rejects))\n",
    "                #print('counter: {} ' .format(counter))\n",
    "        if len(selectList) > 0:\n",
    "            #print('length selectList: {} ' .format(len(selectList)))\n",
    "            dictionary[key][selectKey] = selectList\n",
    "        if len(rejects) > 0:\n",
    "            #print('length rejects: {} ' .format(len(rejects)))\n",
    "            dictionary[key][rejectKey] = rejects\n",
    "    return dictionary\n",
    "\n",
    "def selectIndicesMaker(listKey, sourceKey, indexKey,  newKey, dictionary=femaDict):\n",
    "    '''\n",
    "    returns an input dictionary with new keys based on the input dictionary's sourceKey list:\n",
    "    selectKey has a list containing items found in singleList and the sourceKey list\n",
    "    rejectKey has a list containing items not found in singleList but in the sourceKey list\n",
    "    '''\n",
    "    zeros = [0] * len(dictionary[listKey])\n",
    "    for key, result in getDictLists(sourceKey):\n",
    "        newList = zeros[:]\n",
    "        for word in result:\n",
    "            idx = dictionary[indexKey].get(word)\n",
    "            if idx != None: #can't use simple if because it will discount 0 index\n",
    "                newList[idx] = 1\n",
    "            else:\n",
    "                print(key, word)\n",
    "        dictionary[key][newKey] = newList\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "femaDict = descriptorSelector(listKey ='single descriptors', \n",
    "                              sourceKey='stemmed descriptors', \n",
    "                              selectKey='selected descriptors', \n",
    "                              rejectKey='rejected descriptors')\n",
    "\n",
    "femaDict = selectIndicesMaker(listKey='single descriptors',\n",
    "                              sourceKey='selected descriptors',\n",
    "                              indexKey='descriptor index pairs', \n",
    "                              newKey='descriptor indices')\n",
    "print(femaDict['4713'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def makeDataFrame(listKey, indexKey, dictionary=femaDict):\n",
    "    '''\n",
    "    Returns a pandas DataFrame from lists found in dictionary.\n",
    "    Uses listKey as the column index in DataFrame. \n",
    "    As such listKey list must have the same length as the indexKey list. \n",
    "    Relies  on makeArrayRow function.\n",
    "    '''  \n",
    "    array = [[0]*(len(dictionary[listKey])+1)]#empty row to initialize array. will get ignored downstream\n",
    "    for key, result in getDictLists(indexKey):\n",
    "        newRow = [[int(key)] + result]\n",
    "        array = np.concatenate((array, newRow), axis=0)\n",
    "    data = array[1:,1:] #takes only real data, ignores first filler row and 1st index column\n",
    "    index = array[1:,0] #uses the first column as index\n",
    "    df = pd.DataFrame(data, index=index, columns=dictionary[listKey])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = makeDataFrame('single descriptors', 'descriptor indices')\n",
    "\n",
    "#compares each row in the dataFrame to its counterpart in the dictionary\n",
    "for key, result in getDictLists('descriptor indices'):\n",
    "    if (list(df.loc[int(key)]) != result): \n",
    "        print(key)\n",
    "        break\n",
    "print('All rows in DataArray match!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def makeWordCould(text, title):\n",
    "    wordcloud = WordCloud().generate(text)\n",
    "    plt.figure(figsize = (14,7))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(title, size=30)\n",
    "    plt.show()\n",
    "\n",
    "def listToText(wordList):\n",
    "    '''\n",
    "    input: list of strings (words)\n",
    "    returns: a string made out of the strings in the list separated by spaces\n",
    "    '''\n",
    "    text = ''\n",
    "    for word in wordList:\n",
    "        text = text + ' ' + word\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count = femaDict['single descriptor counts']\n",
    "text = ''\n",
    "for item in count:\n",
    "    for _ in range(item[1]):\n",
    "        text = text + ' ' + item[0]\n",
    "\n",
    "makeWordCould(text, 'Stemmed descriptors used for selection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meatList = list(df[df.meat == 1].index)\n",
    "tallowList = list(df[df.tallow ==1].index)\n",
    "beefList = list(df[df.beef ==1].index)\n",
    "meatIndices = list(set(meatList+tallowList+beefList))\n",
    "len(meatIndices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "meatDescriptors = []\n",
    "for key in meatIndices:\n",
    "    tempList = femaDict[str(key)]['stemmed descriptors']\n",
    "    meatDescriptors.extend(tempList)\n",
    "text = ''\n",
    "for word in meatDescriptors:\n",
    "    text = text + ' ' + word\n",
    "\n",
    "makeWordCould(text, 'Stemmed descriptors in meaty chemicals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meatDescriptors = []\n",
    "for key in meatIndices:\n",
    "    tempList = femaDict[str(key)]['selected descriptors']\n",
    "    meatDescriptors.extend(tempList)\n",
    "text = ''\n",
    "for word in meatDescriptors:\n",
    "    text = text + ' ' + word\n",
    "\n",
    "makeWordCould(text, 'Selected descriptors in meaty chemicals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "X = df.values\n",
    "totalLabels = len(df.columns)\n",
    "nums = []\n",
    "unities = []\n",
    "for num in range(int(totalLabels/2), 0, -1):\n",
    "    kmeans = KMeans(n_clusters=num, random_state=0).fit(X)\n",
    "    dfTest = pd.DataFrame(kmeans.labels_, index = df.index)\n",
    "    labels = dfTest.loc[meatIndices].values.tolist()\n",
    "    labels = [label for lst in labels for label in lst]\n",
    "    unity = len(set(labels))\n",
    "    nums.append(num)\n",
    "    unities.append(unity)\n",
    "    if num%5 == 0:\n",
    "        print(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ratios = np.array(unities)/np.array(nums)\n",
    "\n",
    "plt.figure(1)\n",
    "\n",
    "plt.subplot(221)\n",
    "plt.plot(nums, ratios)\n",
    "plt.axis([0, 40, 0, 1])\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.plot(nums, unities)\n",
    "plt.axis([0, 40, 0, 11])\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.plot(nums, ratios)\n",
    "plt.axis([22, 27, 0.2, 0.5])\n",
    "\n",
    "plt.subplot(224)\n",
    "plt.plot(nums, unities)\n",
    "plt.axis([22, 27, 5, 10])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df.values\n",
    "kmeans = KMeans(n_clusters=25, random_state=0).fit(X)\n",
    "dfTest = pd.DataFrame(kmeans.labels_, index = df.index)\n",
    "labels = dfTest.loc[meatIndices].values.tolist()\n",
    "labels = [label for lst in labels for label in lst]\n",
    "set(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To create word clouds for each of the labels generated at 25 total labels\n",
    "X = df.values\n",
    "kmeans = KMeans(n_clusters=25, random_state=0).fit(X)\n",
    "dfLabels = pd.DataFrame(kmeans.labels_, index = df.index, columns=['labels'])\n",
    "\n",
    "# Determine the labels associated with Meat (meatIndices)\n",
    "labels = dfTest.loc[meatIndices].values #.tolist()\n",
    "labels = [label for lst in labels for label in lst]\n",
    "labelCount = Counter(labels).most_common()\n",
    "labels = set(labels)\n",
    "\n",
    "for label in labels:\n",
    "    descriptors = []\n",
    "    #find the associated fema numbers\n",
    "    femaNums = dfLabels[dfLabels['labels'] == label].index.tolist()\n",
    "    #for each fema number:\n",
    "    for num in femaNums:\n",
    "        #extract the select descriptors\n",
    "        tempList = femaDict[str(num)]['selected descriptors']\n",
    "        #compile a list of the descriptors\n",
    "        descriptors.extend(tempList)\n",
    "    #make a wordCloud\n",
    "    meatCount = [v[1] for v in labelCount if v[0]==label]\n",
    "    title = 'Label: ' + str(label) + '; Number of chemicals: ' + str(meatCount[0]) + '/' +  str(len(femaNums)) \n",
    "    makeWordCould(listToText(descriptors), title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findEmptyKeys(dictionary, descriptorKey):\n",
    "    notEmpty = []\n",
    "    empty = []\n",
    "    \n",
    "    for key in dictionary.keys():\n",
    "        test = dictionary[key].get(descriptorKey)\n",
    "        if test:\n",
    "            notEmpty.append(key)\n",
    "        else:\n",
    "            empty.append(key)\n",
    "    \n",
    "    print('Not empty:\\n')\n",
    "    for item in notEmpty[0:5]:\n",
    "        print(item)\n",
    "    print('\\nEmpty:')\n",
    "    for item in empty[0:5]:\n",
    "        print(item)\n",
    "    \n",
    "    return\n",
    "\n",
    "findEmptyKeys(femaDict, 'select descriptor indices')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
