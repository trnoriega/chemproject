{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEMA website information extraction\n",
    "\n",
    "### The library pages\n",
    "\n",
    "The FEMA website contains a series of [library pages](https://www.femaflavor.org/flavor/library?page=) that list all of the FEMA chemicals.\n",
    "\n",
    "The functions below extract all of the links available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from urllib.request import Request, urlopen\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "\n",
    "def link_to_soup(link, strainer=None):\n",
    "    '''\n",
    "    support function makes a beautiful soup object from link. Disguises itself\n",
    "    as a browser so its not confused for a bot\n",
    "\n",
    "    input:\n",
    "    link: to use as the source for the Beautiful soup object\n",
    "    strainer: can limit the output soup object to a specific type of content\n",
    "\n",
    "    returns:\n",
    "    -Soup object if one can be made\n",
    "    -None otherwise\n",
    "    '''\n",
    "    try:\n",
    "        req = Request(link, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "        page = urlopen(req).read()\n",
    "        soup = BeautifulSoup(page, 'lxml', parse_only=strainer)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fema_link_finder():\n",
    "    \"\"\"\n",
    "    Creates a list of dictionaries with compound names, links and FEMA numbers\n",
    "    based on the FEMA website library pages\n",
    "    \"\"\"\n",
    "    fema_library_link = 'http://www.femaflavor.org/flavor/library?page='\n",
    "    fema_base_link = 'http://www.femaflavor.org'\n",
    "    strainer = SoupStrainer('tbody')\n",
    "    ret_list = []\n",
    "    for i in range(28):\n",
    "        new_link = fema_library_link + str(i)\n",
    "        soup = link_to_soup(new_link, strainer=strainer)\n",
    "        rows = soup.findAll('tr')\n",
    "        \n",
    "        for row in rows:\n",
    "            columns = row.find_all('td')\n",
    "            for col in columns:\n",
    "                if col.string:\n",
    "                    num = int(col.string)\n",
    "                    #print(num)\n",
    "                elif col.a:\n",
    "                    name = str(col.a.string).lower()\n",
    "                    full_link = fema_base_link + col.a.get('href')\n",
    "                    #print(name, full_link)\n",
    "            dicto = {'name': name, 'link': full_link, 'fema': num}\n",
    "            ret_list.append(dicto)\n",
    "            print('.', end='')\n",
    "    \n",
    "    return ret_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fema_links = fema_link_finder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fema_links[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intermediate data dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os.path as path\n",
    "\n",
    "DATA_PATH = path.join(path.expanduser('~'),\n",
    "                     'Dropbox',\n",
    "                     'bymt',\n",
    "                     'data_dumps',\n",
    "                     'chem_project',\n",
    "                     'fema_extraction')\n",
    "\n",
    "fema_links_path = path.join(DATA_PATH, 'fema_links.pkl')\n",
    "\n",
    "# with open(fema_links_path, 'wb') as f:\n",
    "#     pickle.dump(fema_links, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open(fema_links_path, 'rb') as f:\n",
    "    fema_links = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each chemical then has its own page (for example, [acetic acid](https://www.femaflavor.org/acetic-acid-2)) from which I will extract:\n",
    "- Flavor descriptors\n",
    "- Chemical Abstracts Service (CAS) registry number\n",
    "- JECFA number\n",
    "- US Government's Code of Ferderal Regulations (CFR) citation\n",
    "\n",
    "The folowing functions take the data from `fema_links` to get the data from each individual chemical page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from chemspipy import ChemSpider\n",
    "cs = ChemSpider('0201ba66-585d-4135-9e6b-d28ba4724fcf')\n",
    "from rdkit import Chem\n",
    "\n",
    "def link_info(dicto):\n",
    "    \"\"\"\n",
    "    Extract and add descriptors, stems, CAS, JECFA, and CFR numbers to the link_dict,\n",
    "    based on the link provided within link_dict\n",
    "    \"\"\"\n",
    "    link_dict = dicto.copy()\n",
    "    soup = link_to_soup(link_dict['link'])\n",
    "    if soup: \n",
    "        # Get the page title fema number and confirm it matches the number from link_dict\n",
    "        page_titles = soup.find_all('h2', class_='pageTitle')\n",
    "        for res in page_titles:\n",
    "            if len(res.text) > 0:\n",
    "                title = res.text.split('|')\n",
    "                title = [word.strip() for word in title]\n",
    "                title_num = int(title[-1]) #compound number\n",
    "        if title_num != link_dict['fema']:\n",
    "            print('FEMA # from link does not match page title', end=' ')\n",
    "            return None\n",
    "        \n",
    "        # Get the page headings and extract their information\n",
    "        page_headings = soup.find_all('div', class_='field field-type-header')\n",
    "        for item in page_headings:\n",
    "            try:\n",
    "                label = item.find('h3', class_='field-label').stripped_strings\n",
    "                label = list(label)[0]\n",
    "                content = item.find('div', class_='field-item').stripped_strings\n",
    "                content = list(content)[0]\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            if label == 'FLAVOR PROFILE':\n",
    "                link_dict['descriptors'] = content\n",
    "                #lowercase, remove non-word characters (function1), and reduce words\n",
    "                # to their stem (function2)\n",
    "                content.lower()\n",
    "                pattern = re.compile('[\\W_]+')\n",
    "                pattern.sub(' ', content)\n",
    "                stemmer = nltk.stem.SnowballStemmer('english')\n",
    "                stems = [stemmer.stem(word) for word in content.split(' ')]\n",
    "                stems = ' '.join(stems)\n",
    "                link_dict['stems'] = stems\n",
    "            elif label == 'CAS':\n",
    "                link_dict['cas'] = content\n",
    "            elif label == 'JECFA NUMBER':\n",
    "                link_dict['jecfa'] = content\n",
    "            elif label == 'CFR':\n",
    "                link_dict['cfr'] = content\n",
    "        \n",
    "        return link_dict\n",
    "    \n",
    "    else:\n",
    "        print('No soup could be make from the link found')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printed_fema_extraction(dicto_list):\n",
    "    \"\"\"\n",
    "    Create a list of dictionaries with all of the extractable FEMA info.\n",
    "    Displays a readout so that progress is known\n",
    "    \"\"\"\n",
    "    \n",
    "    out = []\n",
    "    total = len(dicto_list)\n",
    "    count = 0\n",
    "    last_displayed = 0\n",
    "    \n",
    "    for dicto in dicto_list:\n",
    "        out.append(link_info(dicto))\n",
    "        \n",
    "        # This noise is all about a nice display with percentage completed\n",
    "        count += 1\n",
    "        val = round((count / total) * 100)\n",
    "        if (val % 5 == 0 and\n",
    "            val != last_displayed):\n",
    "            print('{:2.0f}%' .format(val), end = '.')\n",
    "        else:\n",
    "            print('.', end='')\n",
    "        last_displayed = val\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "............ 5%..............10%..............15%..............20%..............25%..............30%..............35%..............40%..............45%..............50%..............55%..............60%..............65%..............70%..............75%..............80%..............85%..............90%..............95%..............100%.."
     ]
    }
   ],
   "source": [
    "extracted_fema_1 = printed_fema_extraction(fema_links[:280])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "............ 5%..............10%..............15%..............20%..............25%..............30%..............35%..............40%..............45%..............50%..............55%..............60%..............65%..............70%..............75%..............80%..............85%..............90%..............95%..............100%.."
     ]
    }
   ],
   "source": [
    "extracted_fema_2 = printed_fema_extraction(fema_links[280:560])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "............ 5%..............10%..............15%..............20%..............25%..............30%..............35%..............40%..............45%..............50%..............55%..............60%..............65%..............70%..............75%..............80%..............85%..............90%..............95%..............100%.."
     ]
    }
   ],
   "source": [
    "extracted_fema_3 = printed_fema_extraction(fema_links[560:840])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_fema = extracted_fema_1 + extracted_fema_2 + extracted_fema_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "............ 5%..............10%..............15%..............20%..............25%..............30%..............35%..............40%..............45%..............50%..............55%..............60%..............65%..............70%..............75%..............80%..............85%..............90%..............95%..............100%.."
     ]
    }
   ],
   "source": [
    "extracted_fema_4 = printed_fema_extraction(fema_links[840:1120])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "............ 5%..............10%..............15%..............20%..............25%..............30%..............35%..............40%..............45%..............50%..............55%..............60%..............65%..............70%..............75%..............80%..............85%..............90%..............95%..............100%.."
     ]
    }
   ],
   "source": [
    "extracted_fema_5 = printed_fema_extraction(fema_links[1120:1400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "............ 5%..............10%..............15%..............20%..............25%..............30%..............35%..............40%..............45%..............50%..............55%..............60%..............65%..............70%..............75%..............80%..............85%..............90%..............95%..............100%.."
     ]
    }
   ],
   "source": [
    "extracted_fema_6 = printed_fema_extraction(fema_links[1400:1680])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "............ 5%..............10%..............15%..............20%..............25%..............30%..............35%..............40%..............45%..............50%..............55%..............60%..............65%..............70%..............75%..............80%..............85%..............90%..............95%..............100%.."
     ]
    }
   ],
   "source": [
    "extracted_fema_7 = printed_fema_extraction(fema_links[1680:1960])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "extracted_fema = extracted_fema + extracted_fema_4 + extracted_fema_5 +\\\n",
    "                 extracted_fema_6 + extracted_fema_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "............ 5%..............10%..............15%..............20%..............25%..............30%..............35%..............40%..............45%..............50%..............55%..............60%..............65%..............70%..............75%..............80%..............85%..............90%..............95%..............100%.."
     ]
    }
   ],
   "source": [
    "extracted_fema_8 = printed_fema_extraction(fema_links[1960:2240])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "............ 5%..............10%..............15%..............20%..............25%..............30%..............35%..............40%..............45%..............50%..............55%..............60%..............65%..............70%..............75%..............80%..............85%..............90%..............95%..............100%.No soup could be make from the link found\n",
      "."
     ]
    }
   ],
   "source": [
    "extracted_fema_9 = printed_fema_extraction(fema_links[2240:2520])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No soup could be make from the link found\n",
      "............ 5%..............10%.............15%..............20%..............25%..............30%.............35%..............40%..............45%..............50%.............55%..............60%..............65%..............70%.............75%..............80%..............85%..............90%.............95%..............100%.."
     ]
    }
   ],
   "source": [
    "extracted_fema_10 = printed_fema_extraction(fema_links[2520:len(fema_links)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "extracted_fema = extracted_fema + extracted_fema_8 + extracted_fema_9 +\\\n",
    "                 extracted_fema_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length extracted dictionary: 2795 compared to length of links: 2795\n"
     ]
    }
   ],
   "source": [
    "print('Length extracted dictionary: {} compared to length of links: {}' \n",
    "      .format(len(extracted_fema), len(fema_links)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data dump of the final list of dictionaries with the FEMA website information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "extracted_fema_path = path.join(DATA_PATH, 'extracted_fema.pkl')\n",
    "with open(extracted_fema_path, 'wb') as f:\n",
    "    pickle.dump(extracted_fema, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
