{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEMA website information extraction\n",
    "\n",
    "### The library pages\n",
    "\n",
    "The FEMA website contains a series of [library pages](https://www.femaflavor.org/flavor/library?page=) that list all of the FEMA chemicals.\n",
    "\n",
    "The scripts below extract all of the links available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from urllib.request import Request, urlopen\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "\n",
    "def link_to_soup(link, strainer=None):\n",
    "    '''\n",
    "    support function makes a beautiful soup object from link. Disguises itself\n",
    "    as a browser so its not confused for a bot\n",
    "\n",
    "    input:\n",
    "    link: to use as the source for the Beautiful soup object\n",
    "    strainer: can limit the output soup object to a specific type of content\n",
    "\n",
    "    returns:\n",
    "    -Soup object if one can be made\n",
    "    -None otherwise\n",
    "    '''\n",
    "    try:\n",
    "        req = Request(link, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "        page = urlopen(req).read()\n",
    "        soup = BeautifulSoup(page, 'lxml', parse_only=strainer)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fema_link_finder():\n",
    "    \"\"\"\n",
    "    An alternate to the top above dictionary_maker based on finding a\n",
    "    fema list of all compounds and their links\n",
    "    \"\"\"\n",
    "    fema_library_link = 'http://www.femaflavor.org/flavor/library?page='\n",
    "    fema_base_link = 'http://www.femaflavor.org'\n",
    "    strainer = SoupStrainer('tbody')\n",
    "    data = {}\n",
    "    for i in range(28):\n",
    "        new_link = fema_library_link + str(i)\n",
    "        soup = link_to_soup(new_link, strainer=strainer)\n",
    "        rows = soup.findAll('tr')\n",
    "        for row in rows:\n",
    "            columns = row.find_all('td')\n",
    "            for col in columns:\n",
    "                if col.string:\n",
    "                    num = int(col.string)\n",
    "                    data[num] = {}\n",
    "                elif col.a:\n",
    "                    data[num]['name'] = str(col.a.string)\n",
    "                    full_link = fema_base_link + col.a.get('href')\n",
    "                    data[num]['link'] = full_link\n",
    "            print('.', end='')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................."
     ]
    }
   ],
   "source": [
    "fema_links = fema_link_finder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'link': 'http://www.femaflavor.org/acetic-acid-2', 'name': 'ACETIC ACID'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fema_links[2006]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intermediate data dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/TRN/Dropbox/bymt/data_dumps/chem_projectfema_extraction/fema_links.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-50f39d9b15ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mfema_links_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fema_links.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfema_links_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfema_links\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHIGHEST_PROTOCOL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/TRN/Dropbox/bymt/data_dumps/chem_projectfema_extraction/fema_links.pkl'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os.path as path\n",
    "\n",
    "DATA_PATH = path.join(path.expanduser('~'),\n",
    "                     'Dropbox',\n",
    "                     'bymt',\n",
    "                     'data_dumps',\n",
    "                     'chem_project',\n",
    "                     'fema_extraction')\n",
    "\n",
    "fema_links_path = path.join(DATA_PATH, 'fema_links.pkl')\n",
    "\n",
    "with open(fema_links_path, 'wb') as f:\n",
    "    pickle.dump(fema_links, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each chemical then has its own page (for example, [acetic acid](https://www.femaflavor.org/acetic-acid-2)) from which I will extract:\n",
    "- Flavor descriptors\n",
    "- Chemical Abstracts Service (CAS) registry number\n",
    "- JECFA number\n",
    "- US Government's Code of Ferderal Regulations (CFR) citation\n",
    "\n",
    "The folowing functions take the data from `fema_links` to get the data from each individual chemical page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "import re\n",
    "\n",
    "from chemspipy import ChemSpider\n",
    "cs = ChemSpider('0201ba66-585d-4135-9e6b-d28ba4724fcf')\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "from inspect import getmembers, isfunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def search_and_filter(number,\n",
    "                      search_prefix='http://www.femaflavor.org/search/apachesolr_search/',\n",
    "                      substring='/flavor/library/'):\n",
    "    '''\n",
    "    support function for dictionary_maker\n",
    "    searches the Fema website for the number given and\n",
    "    returns a list of links that contain the substring.\n",
    "    Returns None otherwise\n",
    "\n",
    "    Inputs:\n",
    "    -number: Fema number to search for\n",
    "    -search_prefix: web address prefix to search in\n",
    "    -substring: to filter results\n",
    "\n",
    "    Returns:\n",
    "    -page_headings\n",
    "    -name\n",
    "    -link\n",
    "\n",
    "    or\n",
    "    -None if none are found\n",
    "    '''\n",
    "\n",
    "\n",
    "    search_link = search_prefix + str(number)\n",
    "    soup = link_to_soup(search_link)\n",
    "    if soup:\n",
    "        search_block = soup.find_all('dl', class_='search-results apachesolr_search-results')\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    #See if there are any results and extract only the links to flavor compounds\n",
    "    try:\n",
    "        titles = search_block[0].find_all('dt', class_='title')\n",
    "        #extract all search result links\n",
    "        links = [title.find('a').get('href') for title in titles]\n",
    "        #select only links with flavor compund substring\n",
    "        links_checked = [link for link in links if substring in link]\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "    if len(links_checked) >= 1:\n",
    "        for link in links_checked:\n",
    "            print(link)\n",
    "            soup = link_to_soup(link)\n",
    "            if soup:\n",
    "                page_title = soup.find('h2', class_='pageTitle')\n",
    "                page_headings = soup.find_all('div', class_='field field-type-header')\n",
    "                title = page_title.text.split('|')\n",
    "                title = [word.strip() for word in title]\n",
    "                name = title[0] #compound name\n",
    "                title_num = title[-1] #compound number\n",
    "                if title_num == str(number):\n",
    "                    return page_headings, name, link\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def same_chemical(results):\n",
    "    '''\n",
    "    returns an rdkit chemical object if a the chemicals in a chemspipy result list have:\n",
    "    -the same molecular weight, and\n",
    "    -the same smiles representation\n",
    "    returns None otherwise\n",
    "    '''\n",
    "    if results.count == 0:\n",
    "        return None\n",
    "\n",
    "    smiles = []\n",
    "    mws = []\n",
    "\n",
    "    if results.count >= 1:\n",
    "        for chemical in results:\n",
    "            try:\n",
    "                smiles_base = chemical.smiles\n",
    "                chem_base = Chem.MolFromSmiles(smiles_base)\n",
    "\n",
    "                smiles_temp = Chem.MolToSmiles(chem_base)\n",
    "                smiles.append(smiles_temp)\n",
    "\n",
    "                mw_temp = Chem.Descriptors.MolWt(chem_base)\n",
    "                mws.append(mw_temp)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        if (len(set(smiles)) == 1 and\n",
    "                len(set(mws)) == 1):\n",
    "            return Chem.MolFromSmiles(Chem.MolToSmiles(chem_base))\n",
    "\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def chem_search(dict_entry, priotity_list):\n",
    "    '''\n",
    "    returns a rdkit molecule after searching the chemspider database based on the items\n",
    "    in the priority list.\n",
    "    '''\n",
    "\n",
    "    for tup in priotity_list:\n",
    "        try:\n",
    "            tup_string = dict_entry.get(tup[1])\n",
    "        except AttributeError:\n",
    "            continue\n",
    "\n",
    "        if tup_string:\n",
    "            search_string = tup[0] + tup_string\n",
    "            #print('searching for: {}' .format(search_string))\n",
    "            results = cs.search(search_string)\n",
    "            #print('stopped searching')\n",
    "            if same_chemical(results):\n",
    "                #print(tup)\n",
    "                return same_chemical(results)\n",
    "            else:\n",
    "                continue\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dictionary_maker(num_iterator):\n",
    "    '''\n",
    "    returns a dictionary of chemicals found in the femaflavor.org website with FEMA numbers in\n",
    "    the given num_iterator\n",
    "\n",
    "    inputs:\n",
    "    -num_iterator: an iterable object with the fema numbers to be searched\n",
    "\n",
    "    returns:\n",
    "    dictionary with fema number as primary key and the following subkeys:\n",
    "    'link','name', 'descriptors', 'CAS', 'JECFA', 'CFR'\n",
    "    '''\n",
    "\n",
    "    dictionary = {}\n",
    "    count = 0\n",
    "    priority_list = [('fema ', 'FEMA'), ('jecfa ', 'JECFA'), ('', 'CAS'), ('', 'name')]\n",
    "\n",
    "    for number in num_iterator:\n",
    "        #searchNameLink is (pageHeadings, name, link) if there is a FEMA website for number.\n",
    "        # None otherwise\n",
    "        page_name_link = search_and_filter(number)\n",
    "\n",
    "        if page_name_link:\n",
    "            #Add all information from FEMA webpage to dictionary[number][subentries]\n",
    "            dictionary[number] = {}\n",
    "            dictionary[number]['link'] = page_name_link[2]\n",
    "            dictionary[number]['name'] = page_name_link[1]\n",
    "            dictionary[number]['FEMA'] = str(number)\n",
    "            for item in page_name_link[0]:\n",
    "                try:\n",
    "                    label = item.find('h3', class_='field-label').stripped_strings\n",
    "                    label = list(label)[0]\n",
    "                    content = item.find('div', class_='field-item').stripped_strings\n",
    "                    content = list(content)[0]\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "                if label == 'FLAVOR PROFILE':\n",
    "                    dictionary[number]['descriptors'] = content\n",
    "                    #lowercase, remove non-word characters (function1), and reduce words\n",
    "                    # to their stem (function2)\n",
    "                    content.lower()\n",
    "                    pattern = re.compile('[\\W_]+')\n",
    "                    pattern.sub(' ', content)\n",
    "                    stemmer = nltk.stem.SnowballStemmer('english')\n",
    "                    stems = [stemmer.stem(word) for word in content.split(' ')]\n",
    "                    stems = ' '.join(stems)\n",
    "                    text = nltk.word_tokenize(stems)\n",
    "                    tokens = nltk.pos_tag(text)\n",
    "                    selected = [token[0] for token in tokens if token[1] in ['NN', 'JJ']]\n",
    "                    dictionary[number]['tokens'] = selected\n",
    "                elif label == 'CAS':\n",
    "                    dictionary[number]['CAS'] = content\n",
    "                elif label == 'JECFA NUMBER':\n",
    "                    dictionary[number]['JECFA'] = content\n",
    "                elif label == 'CFR':\n",
    "                    dictionary[number]['CFR'] = content\n",
    "\n",
    "            #Add rdkit molecule to dictionary[number]['rdkit Mol']\n",
    "            test = chem_search(dictionary[number], priority_list)\n",
    "            if test:\n",
    "                dictionary[number]['rdkit Mol'] = test\n",
    "            else:\n",
    "                print(' {}nMol' .format(number), end='')\n",
    "\n",
    "        else:\n",
    "            print(' {}nLink' .format(number), end='')\n",
    "\n",
    "        count += 1\n",
    "        if count%10 == 0:\n",
    "            print(' {:.2f}%' .format(count/len(num_iterator)*100), end='')\n",
    "        else:\n",
    "            print('.', end='')\n",
    "    return dictionary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
