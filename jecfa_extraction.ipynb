{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JECFA website information extraction\n",
    "\n",
    "### The alphabetical index\n",
    "\n",
    "The JECFA website contains an [index](http://www.fao.org/food/food-safety-quality/scientific-advice/jecfa/jecfa-flav/browse-alphabetically/en/) with all of the chemicals for which it has information. Javascript is using this [JSON database](http://www.fao.org/food/food-safety-quality/scientific-advice/jecfa/jecfa-flav/browse-alphabetically/jsonlist/en/) to display each of those links\n",
    "\n",
    "The scripts below extract all of the links available from the JSON database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os.path as path\n",
    "\n",
    "DATA_PATH = path.join(path.expanduser('~'),\n",
    "                     'Dropbox',\n",
    "                     'bymt',\n",
    "                     'data_dumps',\n",
    "                     'chem_project',\n",
    "                     'jecfa_extraction')\n",
    "\n",
    "json_path = path.join(DATA_PATH, 'index_links.json')\n",
    "\n",
    "with open(json_path) as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'flavour_name': \"<a  href='food/food-safety-quality/scientific-advice/jecfa/jecfa-flav/details/en/c/2008/'  title=''>(+)-Cedrol</a>\",\n",
       " 'sortfield1': 'C',\n",
       " 'sortfield2': 'Ced',\n",
       " 'sortfield3': 'Cedro'}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def jecfa_link_finder(data):\n",
    "    \"\"\"\n",
    "    Creates a list of dicts with compound names and links based on the json database\n",
    "    used by the JECFA website index page\n",
    "    \"\"\"\n",
    "    BASE_ADDRESS = 'http://www.fao.org/'\n",
    "    ret_list = []\n",
    "    for chemical in data:\n",
    "        link_text = chemical['flavour_name']\n",
    "        soup = BeautifulSoup(link_text, 'lxml')\n",
    "        name = soup.a.text.lower()\n",
    "        link = BASE_ADDRESS + soup.a['href']\n",
    "        dicto = {'name': name, 'link': link}\n",
    "        ret_list.append(dicto)\n",
    "    return ret_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "jecfa_links = jecfa_link_finder(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'link': 'http://www.fao.org/food/food-safety-quality/scientific-advice/jecfa/jecfa-flav/details/en/c/2008/',\n",
       " 'name': '(+)-cedrol'}"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jecfa_links[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual chemical pages\n",
    "\n",
    "Each chemical then has its own page (for example, [acetic acid]http://www.fao.org/food/food-safety-quality/scientific-advice/jecfa/jecfa-flav/details/en/c/3/) from which I will extract:\n",
    "- Odor\n",
    "- Physical form\n",
    "- Synonyms\n",
    "- JECFA, CAS, FEMA numbers\n",
    "\n",
    "The functions below will extract the data\n",
    "\n",
    "Bonuses:\n",
    "- COE, FLAVIS numbers\n",
    "- Molecular weight\n",
    "- Chemical formula\n",
    "- Solubility\n",
    "- Solubility in ethanol\n",
    "- Boiling point\n",
    "- Acid value max\n",
    "- Refractive index\n",
    "- Specific gravity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from urllib.request import Request, urlopen\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "\n",
    "def link_to_soup(link, strainer=None):\n",
    "    '''\n",
    "    support function makes a beautiful soup object from link. Disguises itself\n",
    "    as a browser so its not confused for a bot\n",
    "\n",
    "    returns:\n",
    "    -Soup object if one can be made\n",
    "    -None otherwise\n",
    "    '''\n",
    "    try:\n",
    "        req = Request(link, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "        page = urlopen(req).read()\n",
    "        soup = BeautifulSoup(page, 'lxml', parse_only=strainer)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "REJECT_LABELS = ['latest jecfa evaluation',\n",
    "                 'status of specification', \n",
    "                 'information required',\n",
    "                 'assay min %',\n",
    "                 'id test',\n",
    "                 'spectrum']\n",
    "\n",
    "\n",
    "def link_info(dicto, reject_labels=REJECT_LABELS):\n",
    "    \"\"\"\n",
    "    Extract and add all available information from the JECFA website to dicto,\n",
    "    based on the link provided within dicto\n",
    "    \n",
    "    returns a copy of dicto with extracted information added\n",
    "    \"\"\"\n",
    "    \n",
    "    def is_float(s):\n",
    "        try:\n",
    "            float(s)\n",
    "            return True\n",
    "        except ValueError:\n",
    "            return False\n",
    "    \n",
    "    mod_dicto = dicto.copy()\n",
    "    link = dicto['link']\n",
    "    strainer = SoupStrainer('div',class_='tx-dynafef-pi4')\n",
    "    try:\n",
    "        soup = link_to_soup(link, strainer)\n",
    "        rows = soup.findAll('tr')\n",
    "\n",
    "        for row in rows:\n",
    "            label = row.find('td', class_='label').text.lower()\n",
    "            #remove 'number' from the labels for consistency with FEMA data\n",
    "            label = label.replace('number', '').strip()\n",
    "\n",
    "            # Check if original name and name on website match\n",
    "            if label == 'flavouring':\n",
    "                check_value = row.find('td', class_='value').text.lower()\n",
    "                if check_value != mod_dicto['name']:\n",
    "                    print(\"NAMES DON'T MATCH\")\n",
    "                    return None\n",
    "            elif label not in reject_labels:\n",
    "                value = row.find('td', class_='value').text.lower()\n",
    "                #Convert numbers to ints or floats, EMPTYS TO NaNs\n",
    "                if value.isdigit():\n",
    "                    value = int(value)\n",
    "    #                     print('{} converted to int' .format(value))\n",
    "                #This might cause an issue for flavis but is worth it for molecular weight\n",
    "                elif is_float(value):\n",
    "                    value = float(value)\n",
    "    #                     print('{} converted to float' .format(value))\n",
    "                elif (not value or\n",
    "                    value == 'na'):\n",
    "                    value = 'NaN'\n",
    "    #                 print('{}: {}' .format(label, value))\n",
    "                mod_dicto[label] = value\n",
    "    except:\n",
    "        print('ERROR', end='')\n",
    "        return None\n",
    "    \n",
    "    return mod_dicto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acid value max': 'NaN',\n",
       " 'boiling point (°c)': '60-70° (1-2 mm hg)',\n",
       " 'cas': '437770-28-0',\n",
       " 'chemical formula': 'c12h24o2',\n",
       " 'chemical name': '2,4,8-trimethyl-7-nonen-2-ol',\n",
       " 'coe': 'NaN',\n",
       " 'fema': 4212,\n",
       " 'flavis': 'NaN',\n",
       " 'jecfa': 1644,\n",
       " 'link': 'http://www.fao.org/food/food-safety-quality/scientific-advice/jecfa/jecfa-flav/details/en/c/1633/',\n",
       " 'molecular weight': 184.32,\n",
       " 'name': '(+/-)-2,4,8-trimethyl-7-nonen-2-ol',\n",
       " 'other requirements': 'NaN',\n",
       " 'physical form/odour': 'clear, colourless liquid; fruity aroma',\n",
       " 'refractive index': '1.448-1.455',\n",
       " 'solubility': 'insoluble in water; soluble in non-polar organic solvents',\n",
       " 'solubility in ethanol': 'soluble',\n",
       " 'specific gravity': '0.846-0.853',\n",
       " 'synonym(s)': 'NaN'}"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = link_info(jecfa_links[8])\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def printed_jecfa_extraction(dicto_list):\n",
    "    \"\"\"\n",
    "    Create a list of dictionaries with all of the extractable JECFA info.\n",
    "    Displays a readout so that progress is known\n",
    "    \"\"\"\n",
    "    \n",
    "    out = []\n",
    "    total = len(dicto_list)\n",
    "    count = 0\n",
    "    last_displayed = 0\n",
    "    \n",
    "    for dicto in dicto_list:\n",
    "        out.append(link_info(dicto))\n",
    "        \n",
    "        # This noise is all about a nice display with percentage completed\n",
    "        count += 1\n",
    "        val = round((count / total) * 100)\n",
    "        if (val % 5 == 0 and\n",
    "            val != last_displayed):\n",
    "            print('{:2.0f}%' .format(val), end = '.')\n",
    "        else:\n",
    "            print('.', end='')\n",
    "        last_displayed = val\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10%.20%.30%.40%.50%.60%.70%.ERROR80%.90%.100%."
     ]
    }
   ],
   "source": [
    "test = printed_jecfa_extraction(jecfa_links[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jecfa_chunker(chunkable, splits=10, chunk_number=None):\n",
    "    total = len(chunkable)\n",
    "    chunk_size = round(total/(splits))\n",
    "    start = 0\n",
    "    end = chunk_size\n",
    "    start_end_list = []\n",
    "    while end != total:\n",
    "        start_end_list.append((start, end))\n",
    "        start += chunk_size\n",
    "        end += chunk_size\n",
    "        if end > total:\n",
    "            end = total\n",
    "    start_end_list.append((start,end))\n",
    "        \n",
    "#         print ('Chunk number {}, start: {}, end: {}' .format(i, start, end))\n",
    "#         chunk = chunkable[start:end]\n",
    "#         function(chunk)\n",
    "    return start_end_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(jecfa_chunker(list(range(30))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intermediate step data dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os.path as path\n",
    "\n",
    "DATA_PATH = path.join(path.expanduser('~'),\n",
    "                     'Dropbox',\n",
    "                     'bymt',\n",
    "                     'data_dumps',\n",
    "                     'chem_project')\n",
    "\n",
    "fema_links_path = path.join(DATA_PATH, 'fema_links.pkl')\n",
    "\n",
    "with open(fema_links_path, 'wb') as f:\n",
    "    pickle.dump(fema_links, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "import re\n",
    "\n",
    "from chemspipy import ChemSpider\n",
    "cs = ChemSpider('0201ba66-585d-4135-9e6b-d28ba4724fcf')\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "from inspect import getmembers, isfunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def search_and_filter(number,\n",
    "                      search_prefix='http://www.femaflavor.org/search/apachesolr_search/',\n",
    "                      substring='/flavor/library/'):\n",
    "    '''\n",
    "    support function for dictionary_maker\n",
    "    searches the Fema website for the number given and\n",
    "    returns a list of links that contain the substring.\n",
    "    Returns None otherwise\n",
    "\n",
    "    Inputs:\n",
    "    -number: Fema number to search for\n",
    "    -search_prefix: web address prefix to search in\n",
    "    -substring: to filter results\n",
    "\n",
    "    Returns:\n",
    "    -page_headings\n",
    "    -name\n",
    "    -link\n",
    "\n",
    "    or\n",
    "    -None if none are found\n",
    "    '''\n",
    "\n",
    "\n",
    "    search_link = search_prefix + str(number)\n",
    "    soup = link_to_soup(search_link)\n",
    "    if soup:\n",
    "        search_block = soup.find_all('dl', class_='search-results apachesolr_search-results')\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    #See if there are any results and extract only the links to flavor compounds\n",
    "    try:\n",
    "        titles = search_block[0].find_all('dt', class_='title')\n",
    "        #extract all search result links\n",
    "        links = [title.find('a').get('href') for title in titles]\n",
    "        #select only links with flavor compund substring\n",
    "        links_checked = [link for link in links if substring in link]\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "    if len(links_checked) >= 1:\n",
    "        for link in links_checked:\n",
    "            print(link)\n",
    "            soup = link_to_soup(link)\n",
    "            if soup:\n",
    "                page_title = soup.find('h2', class_='pageTitle')\n",
    "                page_headings = soup.find_all('div', class_='field field-type-header')\n",
    "                title = page_title.text.split('|')\n",
    "                title = [word.strip() for word in title]\n",
    "                name = title[0] #compound name\n",
    "                title_num = title[-1] #compound number\n",
    "                if title_num == str(number):\n",
    "                    return page_headings, name, link\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def same_chemical(results):\n",
    "    '''\n",
    "    returns an rdkit chemical object if a the chemicals in a chemspipy result list have:\n",
    "    -the same molecular weight, and\n",
    "    -the same smiles representation\n",
    "    returns None otherwise\n",
    "    '''\n",
    "    if results.count == 0:\n",
    "        return None\n",
    "\n",
    "    smiles = []\n",
    "    mws = []\n",
    "\n",
    "    if results.count >= 1:\n",
    "        for chemical in results:\n",
    "            try:\n",
    "                smiles_base = chemical.smiles\n",
    "                chem_base = Chem.MolFromSmiles(smiles_base)\n",
    "\n",
    "                smiles_temp = Chem.MolToSmiles(chem_base)\n",
    "                smiles.append(smiles_temp)\n",
    "\n",
    "                mw_temp = Chem.Descriptors.MolWt(chem_base)\n",
    "                mws.append(mw_temp)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        if (len(set(smiles)) == 1 and\n",
    "                len(set(mws)) == 1):\n",
    "            return Chem.MolFromSmiles(Chem.MolToSmiles(chem_base))\n",
    "\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def chem_search(dict_entry, priotity_list):\n",
    "    '''\n",
    "    returns a rdkit molecule after searching the chemspider database based on the items\n",
    "    in the priority list.\n",
    "    '''\n",
    "\n",
    "    for tup in priotity_list:\n",
    "        try:\n",
    "            tup_string = dict_entry.get(tup[1])\n",
    "        except AttributeError:\n",
    "            continue\n",
    "\n",
    "        if tup_string:\n",
    "            search_string = tup[0] + tup_string\n",
    "            #print('searching for: {}' .format(search_string))\n",
    "            results = cs.search(search_string)\n",
    "            #print('stopped searching')\n",
    "            if same_chemical(results):\n",
    "                #print(tup)\n",
    "                return same_chemical(results)\n",
    "            else:\n",
    "                continue\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dictionary_maker(num_iterator):\n",
    "    '''\n",
    "    returns a dictionary of chemicals found in the femaflavor.org website with FEMA numbers in\n",
    "    the given num_iterator\n",
    "\n",
    "    inputs:\n",
    "    -num_iterator: an iterable object with the fema numbers to be searched\n",
    "\n",
    "    returns:\n",
    "    dictionary with fema number as primary key and the following subkeys:\n",
    "    'link','name', 'descriptors', 'CAS', 'JECFA', 'CFR'\n",
    "    '''\n",
    "\n",
    "    dictionary = {}\n",
    "    count = 0\n",
    "    priority_list = [('fema ', 'FEMA'), ('jecfa ', 'JECFA'), ('', 'CAS'), ('', 'name')]\n",
    "\n",
    "    for number in num_iterator:\n",
    "        #searchNameLink is (pageHeadings, name, link) if there is a FEMA website for number.\n",
    "        # None otherwise\n",
    "        page_name_link = search_and_filter(number)\n",
    "\n",
    "        if page_name_link:\n",
    "            #Add all information from FEMA webpage to dictionary[number][subentries]\n",
    "            dictionary[number] = {}\n",
    "            dictionary[number]['link'] = page_name_link[2]\n",
    "            dictionary[number]['name'] = page_name_link[1]\n",
    "            dictionary[number]['FEMA'] = str(number)\n",
    "            for item in page_name_link[0]:\n",
    "                try:\n",
    "                    label = item.find('h3', class_='field-label').stripped_strings\n",
    "                    label = list(label)[0]\n",
    "                    content = item.find('div', class_='field-item').stripped_strings\n",
    "                    content = list(content)[0]\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "                if label == 'FLAVOR PROFILE':\n",
    "                    dictionary[number]['descriptors'] = content\n",
    "                    #lowercase, remove non-word characters (function1), and reduce words\n",
    "                    # to their stem (function2)\n",
    "                    content.lower()\n",
    "                    pattern = re.compile('[\\W_]+')\n",
    "                    pattern.sub(' ', content)\n",
    "                    stemmer = nltk.stem.SnowballStemmer('english')\n",
    "                    stems = [stemmer.stem(word) for word in content.split(' ')]\n",
    "                    stems = ' '.join(stems)\n",
    "                    text = nltk.word_tokenize(stems)\n",
    "                    tokens = nltk.pos_tag(text)\n",
    "                    selected = [token[0] for token in tokens if token[1] in ['NN', 'JJ']]\n",
    "                    dictionary[number]['tokens'] = selected\n",
    "                elif label == 'CAS':\n",
    "                    dictionary[number]['CAS'] = content\n",
    "                elif label == 'JECFA NUMBER':\n",
    "                    dictionary[number]['JECFA'] = content\n",
    "                elif label == 'CFR':\n",
    "                    dictionary[number]['CFR'] = content\n",
    "\n",
    "            #Add rdkit molecule to dictionary[number]['rdkit Mol']\n",
    "            test = chem_search(dictionary[number], priority_list)\n",
    "            if test:\n",
    "                dictionary[number]['rdkit Mol'] = test\n",
    "            else:\n",
    "                print(' {}nMol' .format(number), end='')\n",
    "\n",
    "        else:\n",
    "            print(' {}nLink' .format(number), end='')\n",
    "\n",
    "        count += 1\n",
    "        if count%10 == 0:\n",
    "            print(' {:.2f}%' .format(count/len(num_iterator)*100), end='')\n",
    "        else:\n",
    "            print('.', end='')\n",
    "    return dictionary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
